{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Implementação de um Agente em Flappy Bird"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "couldn't import doomish\n",
      "Couldn't import doom\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import gym_ple\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flappy Bird Sem Visão Computacional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ambiente\n",
    "\n",
    "Modelagem do ambiente do Flappy Bird usando o GameState como observação.\n",
    "\n",
    "#### Observação:\n",
    " * Posição Y do pássaro.\n",
    " * Velocidade Y do pássaro.\n",
    " * Distância do pássaro até o próximo cano.\n",
    " * Posição Y da parte de cima do próximo cano.\n",
    " * Posição Y da parte de baixo do próximo cano.\n",
    " * Distância do pássaro até o cano depois do próximo cano.\n",
    " * Posição Y da parte de cima do cano depois do próximo cano.\n",
    " * Posição Y da parte de baixo do cano depois do próximo cano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlappyBirdEnv(gym.Env):\n",
    "  metadata = {'render.modes': ['human', 'rgb_array']}\n",
    "\n",
    "  def __init__(self):\n",
    "    self.n_pipes = 0\n",
    "    self.env = gym.make(\"FlappyBird-v0\")\n",
    "    # Define action and observation space\n",
    "    # They must be gym.spaces objects\n",
    "    # Example when using discrete actions:\n",
    "    self.action_space = self.env.action_space\n",
    "    # Example for using image as input:\n",
    "    self.observation_space = spaces.Box(low=np.array([0, -10.0, 0, 0, 0, 0, 0, 0]),\n",
    "                                        high=np.array([512, 10.0, 588.0, 512, 512, 588.0, 512, 512]),\n",
    "                                        dtype=np.float32)\n",
    "\n",
    "  def step(self, action):\n",
    "    observation, reward, done, info = self.env.step(action)\n",
    "    observation = np.array(list(self.env.game_state.getGameState().values()))\n",
    "    if reward > 0:\n",
    "        self.n_pipes += reward\n",
    "    if done:\n",
    "        reward = -1\n",
    "    reward += 0.1\n",
    "    reward += (75 - abs(observation[0] - (observation[3] + observation[4])/2))*max((300 - observation[2])/300, 0)/750\n",
    "    return observation, reward, done, info\n",
    "\n",
    "  def reset(self):\n",
    "    self.env.reset()\n",
    "    self.n_pipes = 0\n",
    "    observation = np.array(list(self.env.game_state.getGameState().values()))\n",
    "    return observation  # reward, done, info can't be included\n",
    "\n",
    "  def render(self, mode='human'):\n",
    "    self.env.render(mode='human')\n",
    "    \n",
    "  def close (self):\n",
    "    self.env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checando se o nosso ambiente satisfaz as propriedades do Gym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Environment '<class 'gym_ple.ple_env.PLEEnv'>' has deprecated methods '_step' and '_reset' rather than 'step' and 'reset'. Compatibility code invoked. Set _gym_disable_underscore_compat = True to disable this behavior.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines.common.env_checker import check_env\n",
    "\n",
    "env = FlappyBirdEnv()\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando um vetor com 16 ambientes para multiprocessamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "from stable_baselines.common import set_global_seeds, make_vec_env\n",
    "from stable_baselines.common.vec_env import DummyVecEnv, VecNormalize\n",
    "\n",
    "env = make_vec_env(FlappyBirdEnv, n_envs = 32)\n",
    "env = VecNormalize(env, norm_obs=True, norm_reward=False, clip_obs=10.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando o modelo de PPO2 com a biblioteca Stable Baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\stable_baselines\\common\\policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\stable_baselines\\common\\input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\stable_baselines\\common\\policies.py:561: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F4F9B2B848>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F4F9B2B848>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F4F9B2B848>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F4F9B2B848>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\stable_baselines\\common\\tf_layers.py:123: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F4AF500C08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F4AF500C08>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F4AF500C08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F4AF500C08>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\stable_baselines\\ppo2\\ppo2.py:190: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\stable_baselines\\ppo2\\ppo2.py:206: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\stable_baselines\\ppo2\\ppo2.py:242: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from stable_baselines import PPO2\n",
    "\n",
    "model = PPO2(MlpPolicy, env, n_steps = 1024, learning_rate=0.0001, nminibatches = 64, lam = 0.95, gamma = 0.99, noptepochs= 15, ent_coef= 0.0, cliprange= 0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você tem a opção de usar um modelo pré-treinado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000026892A59A48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000026892A59A48>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000026892A59A48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000026892A59A48>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000026892B9F548>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000026892B9F548>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000026892B9F548>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000026892B9F548>>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines import PPO2\n",
    "\n",
    "model = PPO2.load(\"trained_models/PPO2_1280\")\n",
    "model.set_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando um Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines.common.callbacks import EvalCallback\n",
    "\n",
    "EvalEnv = make_vec_env(FlappyBirdEnv, n_envs = 1)\n",
    "EvalEnv = VecNormalize(EvalEnv, norm_obs=True, norm_reward=False, clip_obs=10.)\n",
    "\n",
    "eval_callback = EvalCallback(EvalEnv, best_model_save_path='./eval_models/',\n",
    "                             log_path='./logs/', n_eval_episodes = 15,\n",
    "                             eval_freq=1024,deterministic=True, render=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinamento do Modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=5920, episode_reward=720.11 +/- 578.65\n",
      "Episode length: 3833.87 +/- 3054.72\n",
      "New best mean reward!\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0027168556  |\n",
      "| clipfrac           | 0.026800537   |\n",
      "| ep_len_mean        | 904           |\n",
      "| ep_reward_mean     | 162           |\n",
      "| explained_variance | -0.578        |\n",
      "| fps                | 63            |\n",
      "| n_updates          | 1             |\n",
      "| policy_entropy     | 0.34100726    |\n",
      "| policy_loss        | -0.0019917767 |\n",
      "| serial_timesteps   | 1024          |\n",
      "| time_elapsed       | 0             |\n",
      "| total_timesteps    | 32768         |\n",
      "| value_loss         | 2.4974778     |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=38688, episode_reward=341.18 +/- 288.56\n",
      "Episode length: 1829.67 +/- 1518.14\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0021577924 |\n",
      "| clipfrac           | 0.021164957  |\n",
      "| ep_len_mean        | 987          |\n",
      "| ep_reward_mean     | 178          |\n",
      "| explained_variance | -1.2         |\n",
      "| fps                | 52           |\n",
      "| n_updates          | 2            |\n",
      "| policy_entropy     | 0.34659368   |\n",
      "| policy_loss        | -0.001977834 |\n",
      "| serial_timesteps   | 2048         |\n",
      "| time_elapsed       | 516          |\n",
      "| total_timesteps    | 65536        |\n",
      "| value_loss         | 2.495526     |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=71456, episode_reward=462.64 +/- 354.97\n",
      "Episode length: 2475.13 +/- 1874.79\n",
      "--------------------------------------\n",
      "| approxkl           | 0.001537003   |\n",
      "| clipfrac           | 0.011183675   |\n",
      "| ep_len_mean        | 1.26e+03      |\n",
      "| ep_reward_mean     | 229           |\n",
      "| explained_variance | -0.753        |\n",
      "| fps                | 59            |\n",
      "| n_updates          | 3             |\n",
      "| policy_entropy     | 0.33871067    |\n",
      "| policy_loss        | -0.0018236472 |\n",
      "| serial_timesteps   | 3072          |\n",
      "| time_elapsed       | 1.14e+03      |\n",
      "| total_timesteps    | 98304         |\n",
      "| value_loss         | 2.4186585     |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=104224, episode_reward=742.11 +/- 559.54\n",
      "Episode length: 3944.07 +/- 2952.77\n",
      "New best mean reward!\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0015990479  |\n",
      "| clipfrac           | 0.0151570635  |\n",
      "| ep_len_mean        | 1.36e+03      |\n",
      "| ep_reward_mean     | 249           |\n",
      "| explained_variance | -1.17         |\n",
      "| fps                | 43            |\n",
      "| n_updates          | 4             |\n",
      "| policy_entropy     | 0.34124848    |\n",
      "| policy_loss        | -0.0015032705 |\n",
      "| serial_timesteps   | 4096          |\n",
      "| time_elapsed       | 1.69e+03      |\n",
      "| total_timesteps    | 131072        |\n",
      "| value_loss         | 2.355376      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines.ppo2.ppo2.PPO2 at 0x1f4860c4dc8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.learn(total_timesteps=524288, callback=eval_callback)\n",
    "model.learn(total_timesteps=131072, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testando o Modelo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestEnv = FlappyBirdEnv()\n",
    "\n",
    "TestEnv = make_vec_env(FlappyBirdEnv, n_envs = 1)\n",
    "TestEnv = VecNormalize(TestEnv, norm_obs=True, norm_reward=False, clip_obs=10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "obs = TestEnv.reset()\n",
    "dones = 0\n",
    "for t in itertools.count():\n",
    "    TestEnv.render()\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = TestEnv.step(action)\n",
    "    if dones:\n",
    "        break\n",
    "    \n",
    "print(t)\n",
    "# print(TestEnv.n_pipes)\n",
    "TestEnv.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salvando o Modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"trained_models/New_PPO2_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gravando um Episódio: (Not Working)\n",
    "\n",
    "Criando o ambiente gravado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines.common.vec_env import VecVideoRecorder, DummyVecEnv\n",
    "\n",
    "video_folder = 'videos/'\n",
    "video_length = 100\n",
    "\n",
    "VideoEnv = DummyVecEnv([lambda: FlappyBirdEnv()])\n",
    "\n",
    "obs = VideoEnv.reset()\n",
    "\n",
    "VideoEnv = VecVideoRecorder(VideoEnv, video_folder,\n",
    "                       record_video_trigger=lambda x: x == 0, video_length=video_length,\n",
    "                       name_prefix=\"FlappyBird\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rodando o episódio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Env returned None on render(). Disabling further rendering for video recorder by marking as disabled: path=D:\\Codigos\\RL\\FlappyBirdPPO2\\videos\\FlappyBird-step-101-to-step-201.mp4 metadata_path=D:\\Codigos\\RL\\FlappyBirdPPO2\\videos\\FlappyBird-step-101-to-step-201.meta.json\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving video to  D:\\Codigos\\RL\\FlappyBirdPPO2\\videos\\FlappyBird-step-101-to-step-201.mp4\n"
     ]
    }
   ],
   "source": [
    "obs = VideoEnv.reset()\n",
    "\n",
    "for _ in range(video_length + 1):\n",
    "    VideoEnv.render()\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, _, _, _ = VideoEnv.step(action)\n",
    "\n",
    "VideoEnv.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flappy Bird com Visão Computacional\n",
    "\n",
    "A implementar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAME = \"FlappyBird-v0\"\n",
    "\n",
    "import gym\n",
    "\n",
    "from stable_baselines.common.policies import CnnLstmPolicy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines import PPO2\n",
    "\n",
    "env_vision = gym.make(ENV_NAME)\n",
    "# Optional: PPO2 requires a vectorized environment to run\n",
    "# the env is now wrapped automatically when passing it to the constructor\n",
    "env_vision = DummyVecEnv([lambda: env_vision])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelVision = PPO2(CnnLstmPolicy, env_vision, n_steps = 512, nminibatches = 1, lam = 0.98, gamma = 0.999, noptepochs= 15, ent_coef= 0.01, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelVision.learn(total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env_vision.reset()\n",
    "dones = 0\n",
    "while not dones:\n",
    "    action, _states = modelVision.predict(obs)\n",
    "    obs, rewards, dones, info = env_vision.step(action)\n",
    "    env.render()\n",
    "\n",
    "env_vision.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
